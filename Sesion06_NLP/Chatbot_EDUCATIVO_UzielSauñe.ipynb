{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a7dfec5",
   "metadata": {},
   "source": [
    "# ğŸ¤– Chatbot educativo â€” FAQ Educativo SintÃ©tico\n",
    "Motores de recuperaciÃ³n:\n",
    "1. TF-IDF + cosine (baseline, interpretable)\n",
    "2. Sentence-BERT (semÃ¡ntico, opcional; con fallback a TF-IDF)\n",
    "Datos: faq_educativo_sintetico.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a34508",
   "metadata": {},
   "source": [
    "## 1) Cargar datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf013da1-664b-46b7-888d-5b17dfd5d011",
   "metadata": {},
   "source": [
    "El sistema inicia cargando el archivo CSV que contiene las preguntas frecuentes educativas. Se verifica que el archivo exista y se lee utilizando pandas. Los datos contienen preguntas, respuestas y categorÃ­as temÃ¡ticas que permiten organizar el conocimiento por materias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b89f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Datos cargados: 50 preguntas en 9 categorÃ­as\n",
      "  CategorÃ­as: BiologÃ­a, Historia, FÃ­sica, Medio ambiente, MatemÃ¡ticas, AstronomÃ­a, QuÃ­mica, GeografÃ­a, Historia de la ciencia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "CSV_PATH = Path(\"faq_educativo_sintetico.csv\")\n",
    "assert CSV_PATH.exists(), \"No se encontrÃ³ faq_educativo_sintetico.csv.\"\n",
    "\n",
    "faq = pd.read_csv(CSV_PATH)\n",
    "print(f\"âœ“ Datos cargados: {len(faq)} preguntas en {faq['refs'].nunique()} categorÃ­as\")\n",
    "print(f\"  CategorÃ­as: {', '.join(faq['refs'].unique())}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705b036d",
   "metadata": {},
   "source": [
    "## 2) TFâ€‘IDF + cosine (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3614b111-6862-4175-9977-0a1b0f8bbfae",
   "metadata": {},
   "source": [
    "Este es el motor base del sistema. Utiliza una tÃ©cnica de vectorizaciÃ³n de texto que analiza la frecuencia de palabras y bigramas en las preguntas. Calcula quÃ© tan similar es la consulta del usuario con cada pregunta almacenada mediante el coseno del Ã¡ngulo entre vectores, devolviendo las mÃ¡s cercanas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec0f088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=1)\n",
    "X = vectorizer.fit_transform(faq[\"question\"].fillna(\"\"))\n",
    "\n",
    "def retrieve_tfidf(query, topk=5):\n",
    "    \"\"\"Recupera las top-k preguntas mÃ¡s similares usando TF-IDF\"\"\"\n",
    "    qv = vectorizer.transform([query])\n",
    "    sims = cosine_similarity(qv, X)[0]\n",
    "    idx = np.argsort(sims)[::-1][:topk]\n",
    "    return [(int(i), float(sims[i])) for i in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4080eae1",
   "metadata": {},
   "source": [
    "## 3) Sentenceâ€‘BERT (opcional) con *fallback*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e9e9c-747e-4f25-8cbc-0c734bd5bace",
   "metadata": {},
   "source": [
    "Es una mejora semÃ¡ntica que utiliza redes neuronales para entender el significado de las oraciones. A diferencia del TF-IDF que solo ve palabras, este motor comprende contexto y sinÃ³nimos. Si no estÃ¡ disponible por problemas de instalaciÃ³n, el sistema automÃ¡ticamente usa el motor TF-IDF como respaldo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a97047d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 20:14:58.105774: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-29 20:14:59.219548: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-29 20:15:02.959653: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  SBERT no disponible; se usarÃ¡ TF-IDF exclusivamente.\n",
      "  Detalle: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "sbert_ready = False\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"â³ Cargando modelo Sentence-BERT...\")\n",
    "    model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "    sbert_ready = True\n",
    "    print(\"âœ“ SBERT cargado exitosamente\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  SBERT no disponible; se usarÃ¡ TF-IDF exclusivamente.\")\n",
    "    print(f\"  Detalle: {e}\\n\")\n",
    "\n",
    "if sbert_ready:\n",
    "    emb_q = model.encode(faq[\"question\"].tolist(), normalize_embeddings=True)\n",
    "    \n",
    "    def retrieve_sbert(query, topk=5):\n",
    "        \"\"\"Recupera usando embeddings semÃ¡nticos de SBERT\"\"\"\n",
    "        q = model.encode([query], normalize_embeddings=True)[0]\n",
    "        sims = emb_q @ q\n",
    "        idx = np.argsort(sims)[::-1][:topk]\n",
    "        return [(int(i), float(sims[i])) for i in idx]\n",
    "else:\n",
    "    def retrieve_sbert(query, topk=5):\n",
    "        \"\"\"Fallback a TF-IDF si SBERT no estÃ¡ disponible\"\"\"\n",
    "        return retrieve_tfidf(query, topk=topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283c8c3",
   "metadata": {},
   "source": [
    "## 4) Respuesta con umbrales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495fd217-c273-4d3d-914d-d47586b6fa10",
   "metadata": {},
   "source": [
    "El sistema evalÃºa la confianza de cada respuesta comparando la similitud obtenida con dos umbrales predefinidos. Si la similitud es alta, responde con certeza. Si es media, sugiere la respuesta pero ofrece alternativas. Si es baja, muestra las opciones mÃ¡s cercanas para que el usuario reformule su pregunta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b53349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD_CERT = 0.55   # Alta confianza\n",
    "THRESHOLD_MAYBE = 0.40  # Confianza media\n",
    "\n",
    "def responder(query, topk=5, metodo=\"auto\"):\n",
    "    \"\"\"\n",
    "    Responde a una consulta del usuario\n",
    "    \n",
    "    Args:\n",
    "        query: Pregunta del usuario\n",
    "        topk: NÃºmero de candidatos a recuperar\n",
    "        metodo: \"tfidf\", \"sbert\" o \"auto\" (usa SBERT si estÃ¡ disponible)\n",
    "    \n",
    "    Returns:\n",
    "        dict con status, match y candidatos\n",
    "    \"\"\"\n",
    "    metodo = metodo.lower()\n",
    "    \n",
    "    # Seleccionar mÃ©todo de recuperaciÃ³n\n",
    "    if metodo == \"tfidf\":\n",
    "        rank = retrieve_tfidf(query, topk=topk)\n",
    "    elif metodo == \"sbert\":\n",
    "        rank = retrieve_sbert(query, topk=topk)\n",
    "    else:  # auto\n",
    "        rank = retrieve_sbert(query, topk=topk)\n",
    "    \n",
    "    if not rank:\n",
    "        return {\n",
    "            \"status\": \"empty\",\n",
    "            \"message\": \"Sin resultados\",\n",
    "            \"candidatos\": []\n",
    "        }\n",
    "    \n",
    "    best_idx, best_sim = rank[0]\n",
    "    \n",
    "    # Formatear candidatos\n",
    "    cand = [{\n",
    "        \"score\": float(sim),\n",
    "        \"question\": faq.iloc[i][\"question\"],\n",
    "        \"answer\": faq.iloc[i][\"answer\"],\n",
    "        \"refs\": faq.iloc[i][\"refs\"]\n",
    "    } for i, sim in rank]\n",
    "    \n",
    "    # Evaluar confianza\n",
    "    if best_sim >= THRESHOLD_CERT:\n",
    "        return {\n",
    "            \"status\": \"ok\",\n",
    "            \"match\": cand[0],\n",
    "            \"candidatos\": cand\n",
    "        }\n",
    "    elif best_sim >= THRESHOLD_MAYBE:\n",
    "        return {\n",
    "            \"status\": \"maybe\",\n",
    "            \"match\": cand[0],\n",
    "            \"candidatos\": cand\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"status\": \"uncertain\",\n",
    "            \"message\": \"No estoy seguro. Â¿Te refieres a alguna de estas preguntas?\",\n",
    "            \"candidatos\": cand\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8bd674",
   "metadata": {},
   "source": [
    "## 5) Chat CLI (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a2cbd-6ce5-4fce-852f-0637a21826bd",
   "metadata": {},
   "source": [
    "Proporciona una interacciÃ³n conversacional en la terminal donde el usuario puede hacer preguntas en lenguaje natural. El sistema responde mostrando la respuesta, el nivel de confianza, la categorÃ­a educativa y sugerencias de preguntas relacionadas cuando es necesario. Incluye comandos para salir de forma amigable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c3265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    \"\"\"Interfaz de chat interactiva en consola\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ¤– Chatbot Educativo â€” FAQ SintÃ©tico\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Escribe 'salir', 'exit' o 'quit' para terminar.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        q = input(\"TÃº: \").strip()\n",
    "        \n",
    "        if q.lower() in {\"salir\", \"exit\", \"quit\"}:\n",
    "            print(\"\\nBot: Â¡Hasta luego! ğŸ‘‹\\n\")\n",
    "            break\n",
    "        \n",
    "        if not q:\n",
    "            continue\n",
    "        \n",
    "        r = responder(q)\n",
    "        \n",
    "        if r[\"status\"] == \"ok\":\n",
    "            m = r[\"match\"]\n",
    "            print(f\"\\nğŸŸ¢ Bot (confianza alta: {m['score']:.2f}):\")\n",
    "            print(f\"   {m['answer']}\")\n",
    "            print(f\"   ğŸ“š CategorÃ­a: {m['refs']}\\n\")\n",
    "            \n",
    "        elif r[\"status\"] == \"maybe\":\n",
    "            m = r[\"match\"]\n",
    "            print(f\"\\nğŸŸ¡ Bot (posible respuesta: {m['score']:.2f}):\")\n",
    "            print(f\"   {m['answer']}\")\n",
    "            print(f\"   ğŸ“š CategorÃ­a: {m['refs']}\")\n",
    "            print(\"\\n   TambiÃ©n podrÃ­as haber preguntado:\")\n",
    "            for s in r[\"candidatos\"][1:3]:\n",
    "                print(f\"   â€¢ {s['question']}\")\n",
    "            print()\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\nğŸ”´ Bot: {r['message']}\")\n",
    "            for s in r[\"candidatos\"][:3]:\n",
    "                print(f\"   â€¢ ({s['score']:.2f}) {s['question']}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b70bad-54c5-4842-ad7e-4c160737ffc5",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# FORMA DE USAR (vease en los resultados cuando se ejecuta)\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edff8f3d-fe0e-440e-89d6-796aea67ea8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Pruebas del sistema:\n",
      "\n",
      "Pregunta: Â¿QuÃ© es la fotosÃ­ntesis?\n",
      "Respuesta (1.00): Es el proceso por el cual las plantas convierten la energÃ­a solar en energÃ­a quÃ­...\n",
      "\n",
      "Pregunta: CuÃ©ntame sobre Albert Einstein\n",
      "Respuesta (0.73): Fue un fÃ­sico alemÃ¡n que desarrollÃ³ la teorÃ­a de la relatividad....\n",
      "\n",
      "Pregunta: Â¿CÃ³mo funciona el reciclaje?\n",
      "Respuesta (0.88): Es el proceso de recolectar y transformar materiales usados en nuevos productos ...\n",
      "\n",
      "Pregunta: Â¿QuÃ© es un nÃºmero primo?\n",
      "Respuesta (1.00): Es un nÃºmero mayor que 1 que solo tiene dos divisores: Ã©l mismo y el 1....\n",
      "\n",
      "\n",
      "============================================================\n",
      "Para iniciar el chat interactivo, ejecuta: chat()\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Pruebas rÃ¡pidas\n",
    "    print(\"ğŸ“ Pruebas del sistema:\\n\")\n",
    "    \n",
    "    ejemplos = [\n",
    "        \"Â¿QuÃ© es la fotosÃ­ntesis?\",\n",
    "        \"CuÃ©ntame sobre Albert Einstein\",\n",
    "        \"Â¿CÃ³mo funciona el reciclaje?\",\n",
    "        \"Â¿QuÃ© es un nÃºmero primo?\"\n",
    "    ]\n",
    "    \n",
    "    for pregunta in ejemplos:\n",
    "        print(f\"Pregunta: {pregunta}\")\n",
    "        resultado = responder(pregunta, topk=3)\n",
    "        if resultado[\"status\"] in [\"ok\", \"maybe\"]:\n",
    "            m = resultado[\"match\"]\n",
    "            print(f\"Respuesta ({m['score']:.2f}): {m['answer'][:80]}...\")\n",
    "        else:\n",
    "            print(f\"Estado: {resultado['status']}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Para iniciar el chat interactivo, ejecuta: chat()\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d416b2b5-1a85-48c4-b294-b5acb87367f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¤– Chatbot Educativo â€” FAQ SintÃ©tico\n",
      "============================================================\n",
      "Escribe 'salir', 'exit' o 'quit' para terminar.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "TÃº:  que es la fotosintesis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¡ Bot (posible respuesta: 0.42):\n",
      "   Es la variedad de organismos vivos que existen en la Tierra.\n",
      "   ğŸ“š CategorÃ­a: Medio ambiente\n",
      "\n",
      "   TambiÃ©n podrÃ­as haber preguntado:\n",
      "   â€¢ Â¿QuÃ© es la velocidad?\n",
      "   â€¢ Â¿QuÃ© es la historia?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "TÃº:  velocidad que es\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¢ Bot (confianza alta: 0.64):\n",
      "   Es la magnitud fÃ­sica que indica la distancia recorrida por un cuerpo en un tiempo determinado.\n",
      "   ğŸ“š CategorÃ­a: FÃ­sica\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "TÃº:  y matematica, que temas sabes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”´ Bot: No estoy seguro. Â¿Te refieres a alguna de estas preguntas?\n",
      "   â€¢ (0.00) Â¿QuÃ© es el calentamiento global?\n",
      "   â€¢ (0.00) Â¿QuÃ© es una media aritmÃ©tica?\n",
      "   â€¢ (0.00) Â¿QuÃ© es la velocidad?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "TÃº:  tema de fisica\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”´ Bot: No estoy seguro. Â¿Te refieres a alguna de estas preguntas?\n",
      "   â€¢ (0.32) Â¿QuÃ© es el reciclaje de papel?\n",
      "   â€¢ (0.31) Â¿QuÃ© es la ley de Ohm?\n",
      "   â€¢ (0.31) Â¿QuÃ© es el teorema de PitÃ¡goras?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "TÃº:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bot: Â¡Hasta luego! ğŸ‘‹\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffea2edb-0331-4a4e-9d0f-36e2d6384932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers<4,>=3.0\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers<4,>=3.0)\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from sentence-transformers<4,>=3.0) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers<4,>=3.0)\n",
      "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from sentence-transformers<4,>=3.0) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from sentence-transformers<4,>=3.0) (1.13.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers<4,>=3.0)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from sentence-transformers<4,>=3.0) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers<4,>=3.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers<4,>=3.0) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers<4,>=3.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers<4,>=3.0) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers<4,>=3.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers<4,>=3.0) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers<4,>=3.0) (75.1.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers<4,>=3.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers<4,>=3.0) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.0 (from torch>=1.11.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers<4,>=3.0) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers<4,>=3.0) (2024.9.11)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers<4,>=3.0)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers<4,>=3.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers<4,>=3.0) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers<4,>=3.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers<4,>=3.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers<4,>=3.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers<4,>=3.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers<4,>=3.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers<4,>=3.0) (2024.8.30)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, safetensors, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-xet, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, sentence-transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.28.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.28.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.28.3\n",
      "Successfully installed hf-xet-1.1.10 huggingface-hub-0.35.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 safetensors-0.6.2 sentence-transformers-3.4.1 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.0 transformers-4.57.1 triton-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"sentence-transformers>=3.0,<4\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27bb5126-bacc-4866-abc4-f2087c3ea0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.12/site-packages (1.2.8)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.12/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.12/site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.12/site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.12/site-packages (from plotly->catboost) (8.2.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 1) Instalar (en el kernel actual)\n",
    "%pip install -q --upgrade pip\n",
    "%pip install lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3634a416-4dee-4529-87b4-c3befe44a0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Info inicial del dataset ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 545 entries, 0 to 544\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   price             545 non-null    int64 \n",
      " 1   area              545 non-null    int64 \n",
      " 2   bedrooms          545 non-null    int64 \n",
      " 3   bathrooms         545 non-null    int64 \n",
      " 4   stories           545 non-null    int64 \n",
      " 5   mainroad          545 non-null    object\n",
      " 6   guestroom         545 non-null    object\n",
      " 7   basement          545 non-null    object\n",
      " 8   hotwaterheating   545 non-null    object\n",
      " 9   airconditioning   545 non-null    object\n",
      " 10  parking           545 non-null    int64 \n",
      " 11  prefarea          545 non-null    object\n",
      " 12  furnishingstatus  545 non-null    object\n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 55.5+ KB\n",
      "\n",
      "=== price_clase creado con umbral [MEDIANA] = 4,340,000.00 ===\n",
      "Regla: price >= umbral => 'MAYOR'; price < umbral => 'MENOR'\n",
      "\n",
      "Conteo de price_clase:\n",
      "price_clase\n",
      "MAYOR    275\n",
      "MENOR    270\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resumen de precios por clase (min/median/max/count):\n",
      "                 min     median       max  count\n",
      "price_clase                                     \n",
      "MAYOR        4340000  5740000.0  13300000    275\n",
      "MENOR        1750000  3430000.0   4319000    270\n",
      "\n",
      "Chequeo: min(MAYOR)=4,340,000.00  vs  max(MENOR)=4,319,000.00\n",
      "\n",
      "Shape: (545, 13) | y(mean): 4766729.2477 | y(std): 1870439.6157 | y[min,max]: (1750000, 13300000)\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 1) Cargar datos y objetivo (Housing.csv)\n",
    "# =========================================\n",
    "import os, json, warnings, platform, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "DATA_FILE = \"Housing.csv\"   # <-- nuestro archivo\n",
    "TARGET    = \"price\"         # variable objetivo continua (regresión)\n",
    "assert os.path.exists(DATA_FILE), f\"No se encuentra {DATA_FILE}\"\n",
    "\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "\n",
    "print(\"\\n=== Info inicial del dataset ===\")\n",
    "df.info()\n",
    "\n",
    "# --------- CONFIG DE UMBRAL PARA price_clase ---------\n",
    "USE_MANUAL_THRESHOLD = False   # True => usar un umbral fijo\n",
    "MANUAL_THRESHOLD     = 3_000_000  # cambia este número si activas el manual\n",
    "\n",
    "if USE_MANUAL_THRESHOLD:\n",
    "    threshold = float(MANUAL_THRESHOLD)\n",
    "    threshold_source = \"MANUAL\"\n",
    "else:\n",
    "    threshold = float(df[TARGET].median())\n",
    "    threshold_source = \"MEDIANA\"\n",
    "\n",
    "# Crear columna auxiliar binaria: MENOR/MAYOR según umbral\n",
    "df[\"price_clase\"] = np.where(df[TARGET] >= threshold, \"MAYOR\", \"MENOR\").astype(str)\n",
    "\n",
    "print(f\"\\n=== price_clase creado con umbral [{threshold_source}] = {threshold:,.2f} ===\")\n",
    "print(\"Regla: price >= umbral => 'MAYOR'; price < umbral => 'MENOR'\")\n",
    "\n",
    "print(\"\\nConteo de price_clase:\")\n",
    "print(df[\"price_clase\"].value_counts())\n",
    "\n",
    "print(\"\\nResumen de precios por clase (min/median/max/count):\")\n",
    "print(\n",
    "    df.groupby(\"price_clase\")[TARGET]\n",
    "      .agg([\"min\",\"median\",\"max\",\"count\"])\n",
    "      .sort_index()\n",
    "      .to_string()\n",
    ")\n",
    "\n",
    "# (Chequeo rápido)\n",
    "min_mayor = df.loc[df[\"price_clase\"]==\"MAYOR\", TARGET].min()\n",
    "max_menor = df.loc[df[\"price_clase\"]==\"MENOR\", TARGET].max()\n",
    "print(f\"\\nChequeo: min(MAYOR)={min_mayor:,.2f}  vs  max(MENOR)={max_menor:,.2f}\")\n",
    "\n",
    "# Definir y (target) y X (features)\n",
    "y = df[TARGET]\n",
    "X = df.drop(columns=[TARGET])\n",
    "\n",
    "print(\"\\nShape:\", X.shape,\n",
    "      \"| y(mean):\", round(y.mean(), 4),\n",
    "      \"| y(std):\",  round(y.std(), 4),\n",
    "      \"| y[min,max]:\", (round(y.min(), 4), round(y.max(), 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156d222a-9435-457c-aba8-915815a5f8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       " 0    7420         4          2        3      yes        no       no   \n",
       " 1    8960         4          4        4      yes        no       no   \n",
       " 2    9960         3          2        2      yes        no      yes   \n",
       " 3    7500         4          2        2      yes        no      yes   \n",
       " 4    7420         4          1        2      yes       yes      yes   \n",
       " ..    ...       ...        ...      ...      ...       ...      ...   \n",
       " 540  3000         2          1        1      yes        no      yes   \n",
       " 541  2400         3          1        1       no        no       no   \n",
       " 542  3620         2          1        1      yes        no       no   \n",
       " 543  2910         3          1        1       no        no       no   \n",
       " 544  3850         3          1        2      yes        no       no   \n",
       " \n",
       "     hotwaterheating airconditioning  parking prefarea furnishingstatus  \\\n",
       " 0                no             yes        2      yes        furnished   \n",
       " 1                no             yes        3       no        furnished   \n",
       " 2                no              no        2      yes   semi-furnished   \n",
       " 3                no             yes        3      yes        furnished   \n",
       " 4                no             yes        2       no        furnished   \n",
       " ..              ...             ...      ...      ...              ...   \n",
       " 540              no              no        2       no      unfurnished   \n",
       " 541              no              no        0       no   semi-furnished   \n",
       " 542              no              no        0       no      unfurnished   \n",
       " 543              no              no        0       no        furnished   \n",
       " 544              no              no        0       no      unfurnished   \n",
       " \n",
       "     price_clase  \n",
       " 0         MAYOR  \n",
       " 1         MAYOR  \n",
       " 2         MAYOR  \n",
       " 3         MAYOR  \n",
       " 4         MAYOR  \n",
       " ..          ...  \n",
       " 540       MENOR  \n",
       " 541       MENOR  \n",
       " 542       MENOR  \n",
       " 543       MENOR  \n",
       " 544       MENOR  \n",
       " \n",
       " [545 rows x 13 columns],\n",
       " 0      13300000\n",
       " 1      12250000\n",
       " 2      12250000\n",
       " 3      12215000\n",
       " 4      11410000\n",
       "          ...   \n",
       " 540     1820000\n",
       " 541     1767150\n",
       " 542     1750000\n",
       " 543     1750000\n",
       " 544     1750000\n",
       " Name: price, Length: 545, dtype: int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a612b1-8c83-4b7e-aa82-f8b98dbd3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (436, 12) | Test: (109, 12)\n",
      "¿'price_clase' en X_train? False\n",
      "\n",
      "Distribución price_clase (proporción):\n",
      "Train:\n",
      " price_clase\n",
      "MAYOR    0.505\n",
      "MENOR    0.495\n",
      "Name: proportion, dtype: float64\n",
      "Test:\n",
      " price_clase\n",
      "MAYOR    0.505\n",
      "MENOR    0.495\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 2) Split temprano (80/20)\n",
    "# =========================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Evitar fuga de datos: quitar cualquier columna derivada del target\n",
    "LEAKAGE_COLS = [\"price_clase\"]  # auxiliar EDA, no debe ir a features\n",
    "X_noleak = X.drop(columns=[c for c in LEAKAGE_COLS if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "# (Opcional) estratificación por la clase auxiliar para mantener distribución\n",
    "USE_STRATIFY = True and (\"price_clase\" in df.columns)\n",
    "stratify_vec = df[\"price_clase\"] if USE_STRATIFY else None\n",
    "\n",
    "if stratify_vec is not None:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_noleak, y, test_size=0.20, random_state=RANDOM_STATE, stratify=stratify_vec\n",
    "    )\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_noleak, y, test_size=0.20, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "print(f\"Train: {X_train.shape} | Test: {X_test.shape}\")\n",
    "print(\"¿'price_clase' en X_train?\", \"price_clase\" in X_train.columns)\n",
    "\n",
    "# (Diagnóstico opcional de la estratificación)\n",
    "if \"price_clase\" in df.columns:\n",
    "    train_idx = X_train.index\n",
    "    test_idx  = X_test.index\n",
    "    print(\"\\nDistribución price_clase (proporción):\")\n",
    "    print(\"Train:\\n\", df.loc[train_idx, \"price_clase\"].value_counts(normalize=True).round(3))\n",
    "    print(\"Test:\\n\",  df.loc[test_idx,  \"price_clase\"].value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7c6dca-37f3-469d-8842-e333cbda85bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features numéricas (5): ['area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
      "Features categóricas (7): ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'furnishingstatus']\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 3) Preprocesamiento (en pipeline)\n",
    "# =========================================\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Fallback si no tienes imblearn instalado\n",
    "try:\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline  # imblearn solo por consistencia de API\n",
    "except Exception:\n",
    "    from sklearn.pipeline import Pipeline as ImbPipeline\n",
    "    print(\"[AVISO] imblearn no disponible; usando sklearn.Pipeline como fallback.\")\n",
    "\n",
    "# Detectar tipos desde el split ya hecho (X_train)\n",
    "cat_features = X_train.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "num_features = X_train.select_dtypes(include=[\"number\",\"bool\"]).columns.tolist()\n",
    "\n",
    "# OneHotEncoder compatible (con fallback segun versión de sklearn)\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_features),\n",
    "        (\"cat\", ohe,              cat_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "def build_pipe(model):\n",
    "    # Nota: en regresión NO se usa SMOTE\n",
    "    return ImbPipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"var0\", VarianceThreshold(0.0)),  # limpia columnas constantes tras OHE\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "print(f\"Features numéricas ({len(num_features)}): {num_features}\")\n",
    "print(f\"Features categóricas ({len(cat_features)}): {cat_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fbc8485-a82e-4c51-8a61-c2a4955fb856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost : True\n",
      "lightgbm: True\n",
      "catboost: True\n",
      "candidatos: ['LR', 'RG', 'LS', 'EN', 'KNR', 'DTR', 'RFR', 'MLP', 'XGB', 'LGB', 'CAT'] => 11\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 4) Modelos candidatos (REGRESIÓN) - sin prints de training\n",
    "# =========================================\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "HAVE_XGB = True\n",
    "HAVE_LGB = True\n",
    "HAVE_CAT = True\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "except Exception:\n",
    "    HAVE_XGB = False\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "except Exception:\n",
    "    HAVE_LGB = False\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "except Exception:\n",
    "    HAVE_CAT = False\n",
    "\n",
    "candidates = [\n",
    "    (\"LR\",  LinearRegression()),\n",
    "    (\"RG\",  Ridge()),  # Ridge no recibe random_state\n",
    "    (\"LS\",  Lasso(max_iter=5000)),\n",
    "    (\"EN\",  ElasticNet(max_iter=5000)),\n",
    "    (\"KNR\", KNeighborsRegressor()),\n",
    "    (\"DTR\", DecisionTreeRegressor(random_state=RANDOM_STATE)),\n",
    "    (\"RFR\", RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1)),\n",
    "    (\"MLP\", MLPRegressor(hidden_layer_sizes=(64,), max_iter=800, random_state=RANDOM_STATE)),\n",
    "]\n",
    "\n",
    "if HAVE_XGB:\n",
    "    candidates.append((\"XGB\", XGBRegressor(\n",
    "        tree_method=\"hist\", random_state=RANDOM_STATE,\n",
    "        n_estimators=400, learning_rate=0.05, max_depth=6,\n",
    "        subsample=0.9, colsample_bytree=0.9, n_jobs=-1,\n",
    "        verbosity=0               # << silencia logs de XGBoost\n",
    "    )))\n",
    "\n",
    "if HAVE_LGB:\n",
    "    candidates.append((\"LGB\", LGBMRegressor(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=-1,\n",
    "        subsample=0.9, colsample_bytree=0.9,\n",
    "        random_state=RANDOM_STATE, n_jobs=-1,\n",
    "        verbosity=-1,             # << silencia logs de LightGBM\n",
    "        force_row_wise=True       # << evita el mensaje de auto-choosing\n",
    "    )))\n",
    "\n",
    "if HAVE_CAT:\n",
    "    candidates.append((\"CAT\", CatBoostRegressor(\n",
    "        iterations=600, learning_rate=0.05, depth=6,\n",
    "        random_state=RANDOM_STATE, l2_leaf_reg=3.0,\n",
    "        verbose=False,            # << silencia logs de CatBoost\n",
    "        allow_writing_files=False,\n",
    "        thread_count=-1\n",
    "    )))\n",
    "\n",
    "# (comprobación de entorno/candidatos - útil para debug)\n",
    "import importlib.util\n",
    "print(\"xgboost :\", importlib.util.find_spec(\"xgboost\")  is not None)\n",
    "print(\"lightgbm:\", importlib.util.find_spec(\"lightgbm\") is not None)\n",
    "print(\"catboost:\", importlib.util.find_spec(\"catboost\") is not None)\n",
    "print(\"candidatos:\", [n for n,_ in candidates], \"=>\", len(candidates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b245143-7bd0-4971-999f-4955066c979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LR | RMSE 1082081.838 | MAE 792713.122 | R² 0.656\n",
      " RG | RMSE 1081743.895 | MAE 792140.372 | R² 0.656\n",
      " LS | RMSE 1082081.859 | MAE 792712.631 | R² 0.656\n",
      " EN | RMSE 1146338.654 | MAE 822021.674 | R² 0.622\n",
      "KNR | RMSE 1181777.394 | MAE 807823.280 | R² 0.593\n",
      "DTR | RMSE 1729343.472 | MAE 1161767.259 | R² 0.010\n",
      "RFR | RMSE 1139928.003 | MAE 825509.582 | R² 0.614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP | RMSE 5126149.309 | MAE 4770977.038 | R² -6.736\n",
      "XGB | RMSE 1140259.901 | MAE 817866.062 | R² 0.611\n",
      "LGB | RMSE 1196549.497 | MAE 848169.670 | R² 0.560\n",
      "CAT | RMSE 1085242.809 | MAE 768188.571 | R² 0.649\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RG</td>\n",
       "      <td>1.081744e+06</td>\n",
       "      <td>7.921404e+05</td>\n",
       "      <td>0.656369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>1.082082e+06</td>\n",
       "      <td>7.927131e+05</td>\n",
       "      <td>0.656086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LS</td>\n",
       "      <td>1.082082e+06</td>\n",
       "      <td>7.927126e+05</td>\n",
       "      <td>0.656086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAT</td>\n",
       "      <td>1.085243e+06</td>\n",
       "      <td>7.681886e+05</td>\n",
       "      <td>0.649025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RFR</td>\n",
       "      <td>1.139928e+06</td>\n",
       "      <td>8.255096e+05</td>\n",
       "      <td>0.614322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB</td>\n",
       "      <td>1.140260e+06</td>\n",
       "      <td>8.178661e+05</td>\n",
       "      <td>0.611027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EN</td>\n",
       "      <td>1.146339e+06</td>\n",
       "      <td>8.220217e+05</td>\n",
       "      <td>0.621653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNR</td>\n",
       "      <td>1.181777e+06</td>\n",
       "      <td>8.078233e+05</td>\n",
       "      <td>0.593410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LGB</td>\n",
       "      <td>1.196549e+06</td>\n",
       "      <td>8.481697e+05</td>\n",
       "      <td>0.559828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DTR</td>\n",
       "      <td>1.729343e+06</td>\n",
       "      <td>1.161767e+06</td>\n",
       "      <td>0.009863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLP</td>\n",
       "      <td>5.126149e+06</td>\n",
       "      <td>4.770977e+06</td>\n",
       "      <td>-6.735730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model          rmse           mae        r2\n",
       "0     RG  1.081744e+06  7.921404e+05  0.656369\n",
       "1     LR  1.082082e+06  7.927131e+05  0.656086\n",
       "2     LS  1.082082e+06  7.927126e+05  0.656086\n",
       "3    CAT  1.085243e+06  7.681886e+05  0.649025\n",
       "4    RFR  1.139928e+06  8.255096e+05  0.614322\n",
       "5    XGB  1.140260e+06  8.178661e+05  0.611027\n",
       "6     EN  1.146339e+06  8.220217e+05  0.621653\n",
       "7    KNR  1.181777e+06  8.078233e+05  0.593410\n",
       "8    LGB  1.196549e+06  8.481697e+05  0.559828\n",
       "9    DTR  1.729343e+06  1.161767e+06  0.009863\n",
       "10   MLP  5.126149e+06  4.770977e+06 -6.735730"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Baseline ganador: RG\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 5) Baseline con CV (sin tuning) - adaptado\n",
    "# =========================================\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import pandas as pd\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "scoring = {\n",
    "    \"rmse\": \"neg_root_mean_squared_error\",\n",
    "    \"mae\":  \"neg_mean_absolute_error\",\n",
    "    \"r2\":   \"r2\",\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, model in candidates:\n",
    "    pipe = build_pipe(model)  # usa el preprocessor del Paso 3\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    row = {\n",
    "        \"model\": name,\n",
    "        \"rmse\": -scores[\"test_rmse\"].mean(),  # pasar a positivo\n",
    "        \"mae\":  -scores[\"test_mae\"].mean(),\n",
    "        \"r2\":    scores[\"test_r2\"].mean(),\n",
    "    }\n",
    "    rows.append(row)\n",
    "    print(f\"{name:>3} | RMSE {row['rmse']:.3f} | MAE {row['mae']:.3f} | R² {row['r2']:.3f}\")\n",
    "\n",
    "baseline_df = pd.DataFrame(rows).sort_values(\"rmse\").reset_index(drop=True)\n",
    "\n",
    "# display para notebooks, fallback a print si no existe display()\n",
    "try:\n",
    "    display(baseline_df)\n",
    "except Exception:\n",
    "    print(\"\\nBaseline CV:\")\n",
    "    print(baseline_df.to_string(index=False))\n",
    "\n",
    "baseline_best_name  = baseline_df.iloc[0][\"model\"]\n",
    "baseline_best_model = dict(candidates)[baseline_best_name]\n",
    "print(f\">>> Baseline ganador: {baseline_best_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92f232e5-0ca2-4e97-9cc8-9b074a6f8f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+14, tolerance: 1.378e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.750e+14, tolerance: 1.213e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e+14, tolerance: 1.229e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+14, tolerance: 1.171e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e+14, tolerance: 1.350e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GANADOR OPTIMIZADO: EN (RMSE CV=1080759.666)\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 6) Tuning con CV y elección del ganador (rápido) - silencioso\n",
    "# =========================================\n",
    "import tempfile, shutil, numpy as np\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "try:\n",
    "    from scipy.stats import loguniform\n",
    "except Exception:\n",
    "    from sklearn.utils.fixes import loguniform\n",
    "\n",
    "# CV \"ligero\" para modelos simples, \"pesado\" para tree/boosters\n",
    "cv_light = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_heavy = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Espacios de búsqueda (usamos el prefijo 'model__' porque en build_pipe el estimador se llama 'model')\n",
    "param_spaces = {\n",
    "    \"RG\":  {\"model__alpha\": loguniform(1e-3, 1e3)},\n",
    "    \"LS\":  {\"model__alpha\": loguniform(1e-3, 1e2)},\n",
    "    \"EN\":  {\"model__alpha\": loguniform(1e-3, 1e2), \"model__l1_ratio\": uniform(0.0, 1.0)},\n",
    "    \"KNR\": {\"model__n_neighbors\": randint(2, 50), \"model__weights\": [\"uniform\",\"distance\"], \"model__p\":[1,2]},\n",
    "    \"DTR\": {\"model__max_depth\": randint(3, 16), \"model__min_samples_leaf\": randint(1, 10)},\n",
    "    \"RFR\": {\"model__n_estimators\": randint(200, 600), \"model__max_depth\": randint(4, 16),\n",
    "            \"model__min_samples_split\": randint(2, 20), \"model__min_samples_leaf\": randint(1, 10),\n",
    "            \"model__max_features\": [\"sqrt\",\"log2\", None], \"model__bootstrap\": [True, False]},\n",
    "    \"MLP\": {\"model__alpha\": loguniform(1e-4, 1e-1), \"model__learning_rate_init\": loguniform(1e-4, 1e-2)},\n",
    "    \"XGB\": {\"model__n_estimators\": randint(250, 600), \"model__learning_rate\": loguniform(5e-3, 2e-1),\n",
    "            \"model__max_depth\": randint(3, 9), \"model__subsample\": uniform(0.7, 0.3),\n",
    "            \"model__colsample_bytree\": uniform(0.7, 0.3), \"model__min_child_weight\": randint(1, 6)},\n",
    "    \"LGB\": {\"model__n_estimators\": randint(300, 800), \"model__learning_rate\": loguniform(5e-3, 2e-1),\n",
    "            \"model__num_leaves\": randint(16, 128), \"model__max_depth\": randint(-1, 12),\n",
    "            \"model__min_child_samples\": randint(10, 50), \"model__subsample\": uniform(0.7, 0.3),\n",
    "            \"model__colsample_bytree\": uniform(0.7, 0.3), \"model__reg_lambda\": loguniform(1e-3, 10)},\n",
    "    \"CAT\": {\"model__iterations\": randint(300, 700), \"model__learning_rate\": loguniform(5e-3, 2e-1),\n",
    "            \"model__depth\": randint(4, 10), \"model__l2_leaf_reg\": loguniform(1e-2, 30),\n",
    "            \"model__border_count\": randint(32, 255)},\n",
    "}\n",
    "\n",
    "# Elegimos qué modelos tunear (puedes ajustar esta lista; dejo los más relevantes)\n",
    "to_tune = [\n",
    "    (\"RG\",  Ridge()),  # Ridge no tiene random_state\n",
    "    (\"EN\",  ElasticNet(random_state=RANDOM_STATE, max_iter=5000)),\n",
    "    (\"RFR\", RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=1)),\n",
    "]\n",
    "\n",
    "# Añadimos boosters si están disponibles (según flags del Paso 4)\n",
    "if 'HAVE_XGB' in globals() and HAVE_XGB:\n",
    "    to_tune.append((\"XGB\", XGBRegressor(\n",
    "        tree_method=\"hist\", random_state=RANDOM_STATE, n_jobs=1, verbosity=0\n",
    "    )))\n",
    "if 'HAVE_LGB' in globals() and HAVE_LGB:\n",
    "    to_tune.append((\"LGB\", LGBMRegressor(\n",
    "        random_state=RANDOM_STATE, n_jobs=1, verbosity=-1, force_row_wise=True\n",
    "    )))\n",
    "if 'HAVE_CAT' in globals() and HAVE_CAT:\n",
    "    to_tune.append((\"CAT\", CatBoostRegressor(\n",
    "        random_state=RANDOM_STATE, verbose=False, allow_writing_files=False, thread_count=1\n",
    "    )))\n",
    "\n",
    "refit_metric = \"rmse\"  # minimizamos RMSE\n",
    "scoring = {\"rmse\": \"neg_root_mean_squared_error\", \"mae\": \"neg_mean_absolute_error\", \"r2\": \"r2\"}\n",
    "\n",
    "best_models = []\n",
    "cache_dir = tempfile.mkdtemp(prefix=\"skcache_\")\n",
    "try:\n",
    "    for name, base_model in to_tune:\n",
    "        pipe = build_pipe(base_model)\n",
    "        # intentar cachear transformaciones (si fuera sklearn.Pipeline); en imblearn no aplica\n",
    "        try:\n",
    "            pipe.set_params(memory=cache_dir)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        heavy = name in [\"RFR\", \"XGB\", \"LGB\", \"CAT\"]\n",
    "        search = RandomizedSearchCV(\n",
    "            pipe, param_spaces[name],\n",
    "            n_iter=(15 if heavy else 12),\n",
    "            cv=(cv_heavy if heavy else cv_light),\n",
    "            scoring=scoring, refit=refit_metric,\n",
    "            n_jobs=-1, random_state=RANDOM_STATE, verbose=0,\n",
    "            error_score=np.nan, return_train_score=False\n",
    "        )\n",
    "        search.fit(X_train, y_train)\n",
    "        # Guardamos: nombre, mejor pipeline, RMSE CV positivo, y params ganadores\n",
    "        best_models.append((name, search.best_estimator_, -search.best_score_, search.best_params_))\n",
    "\n",
    "    # ordenamos por menor RMSE CV\n",
    "    best_models.sort(key=lambda x: x[2])\n",
    "    best_name, final_pipe_opt, best_cv_rmse, best_params = best_models[0]\n",
    "    # print mínimo (puedes comentar esta línea si quieres 100% silencio)\n",
    "    print(f\">>> GANADOR OPTIMIZADO: {best_name} (RMSE CV={best_cv_rmse:.3f})\")\n",
    "finally:\n",
    "    shutil.rmtree(cache_dir, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b5e18a-312c-493f-b3c1-31a0d8ea58ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline(RG): RMSE 1074381.5158\n",
      "Tuned(EN): RMSE 1073456.8307\n",
      ">>> Modelo seleccionado para TEST: RG\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 7) Comparación justa (solo CV) - baseline vs ganador\n",
    "# =========================================\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "same_cv = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "pipe_baseline_best = build_pipe(baseline_best_model)  # del Paso 5\n",
    "pipe_tuned_best    = final_pipe_opt                   # del Paso 6\n",
    "\n",
    "def cv_rmse(pipe, name):\n",
    "    s = cross_validate(\n",
    "        pipe, X_train, y_train, cv=same_cv,\n",
    "        scoring={\"rmse\":\"neg_root_mean_squared_error\"},\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rmse = -s[\"test_rmse\"].mean()\n",
    "    print(f\"{name}: RMSE {rmse:.4f}\")\n",
    "    return rmse\n",
    "\n",
    "rmse_base = cv_rmse(pipe_baseline_best, f\"Baseline({baseline_best_name})\")\n",
    "rmse_tune = cv_rmse(pipe_tuned_best,   f\"Tuned({best_name})\")\n",
    "\n",
    "# Regla: si la mejora < 1% del RMSE base, nos quedamos con el baseline (más simple)\n",
    "if (rmse_base - rmse_tune) / rmse_base >= 0.01:\n",
    "    winner_name, winner_pipe = best_name, pipe_tuned_best\n",
    "else:\n",
    "    winner_name, winner_pipe = baseline_best_name, pipe_baseline_best\n",
    "\n",
    "print(f\">>> Modelo seleccionado para TEST: {winner_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9156f243-260e-43cc-b487-d5a1eb1f0fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Política: {'clip_to_train_range': True, 'round_to_int': False, 'lower': 1750000.0, 'upper': 13300000.0}\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 8) Política de decisión (mínima)\n",
    "# =========================================\n",
    "POLICY = {\n",
    "    \"clip_to_train_range\": True,   # recorta predicciones al rango visto en TRAIN\n",
    "    \"round_to_int\": False,         # para 'price' normalmente False; cámbialo si quisieras enteros\n",
    "    \"lower\": float(y_train.min()),\n",
    "    \"upper\": float(y_train.max()),\n",
    "}\n",
    "print(\"Política:\", POLICY)\n",
    "\n",
    "def postprocess_preds(yhat, policy=POLICY):\n",
    "    # yhat puede ser np.array o pd.Series\n",
    "    ypp = np.array(yhat, copy=True)\n",
    "    if policy.get(\"clip_to_train_range\", False):\n",
    "        ypp = np.clip(ypp, policy[\"lower\"], policy[\"upper\"])\n",
    "    if policy.get(\"round_to_int\", False):\n",
    "        ypp = np.rint(ypp).astype(int)\n",
    "    return ypp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "292e9f62-5cb2-4de1-85c6-6ebcf4c98acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST → RMSE: 1141352.9511 | MAE: 866833.4836 | R²: 0.5501\n",
      "   y_true    y_pred      y_pp\n",
      "3,010,000 3,342,386 3,342,386\n",
      "3,570,000 2,553,527 2,553,527\n",
      "4,340,000 6,379,273 6,379,273\n",
      "2,450,000 3,537,262 3,537,262\n",
      "5,950,000 6,633,327 6,633,327\n",
      "3,010,000 3,165,220 3,165,220\n",
      "5,110,000 5,647,763 5,647,763\n",
      "4,550,000 3,633,258 3,633,258\n",
      "3,850,000 5,536,154 5,536,154\n",
      "5,320,000 6,053,505 6,053,505\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 9) Evaluación final en TEST\n",
    "# =========================================\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# winner_pipe viene del Paso 7 (RG en tu corrida)\n",
    "winner_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predicción y postproceso según POLICY\n",
    "y_pred = winner_pipe.predict(X_test)\n",
    "y_pp   = postprocess_preds(y_pred, POLICY)\n",
    "\n",
    "# Métricas en TEST\n",
    "rmse = mean_squared_error(y_test, y_pp, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pp)\n",
    "r2   = r2_score(y_test, y_pp)\n",
    "\n",
    "print(f\"TEST → RMSE: {rmse:.4f} | MAE: {mae:.4f} | R²: {r2:.4f}\")\n",
    "\n",
    "# Vistazo rápido (primeros 10)\n",
    "import pandas as pd\n",
    "formatters = {\n",
    "    \"y_true\": lambda v: f\"{v:,.0f}\",\n",
    "    \"y_pred\": lambda v: f\"{v:,.0f}\",   # sin postproceso (por si quieres comparar)\n",
    "    \"y_pp\":   lambda v: f\"{v:,.0f}\",      # con postproceso/policy aplicada\n",
    "}\n",
    "print(preview.head(10).to_string(index=False, formatters=formatters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99525c07-ca07-4dc0-9ef3-02a1246ecb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Policy] clipped_low: 0.000% | clipped_high: 0.000%\n",
      "\n",
      "Top-15 importancias (perm, columnas originales):\n",
      "         feature  importance       std\n",
      "            area  182,344.97 31,838.60\n",
      "       bathrooms  138,846.63 37,007.56\n",
      "         stories   94,767.63 35,128.32\n",
      "        prefarea   65,560.80 22,681.02\n",
      " airconditioning   60,723.48 53,230.88\n",
      "         parking   52,479.10 18,063.67\n",
      "        basement   36,486.61  9,352.47\n",
      " hotwaterheating   28,435.66 13,993.86\n",
      "       guestroom   18,102.43  8,385.11\n",
      "        mainroad   17,821.57 15,938.97\n",
      "        bedrooms   -2,385.15  9,968.92\n",
      "furnishingstatus   -3,750.82 27,719.17\n",
      "\n",
      "Resumen de |error|:\n",
      "count         109.00\n",
      "mean      866,833.48\n",
      "std       745,916.06\n",
      "min         3,031.60\n",
      "10%       123,765.02\n",
      "25%       356,997.61\n",
      "50%       691,088.47\n",
      "75%     1,038,287.91\n",
      "90%     2,063,355.89\n",
      "max     3,509,401.43\n",
      "\n",
      "Peores 10 casos (|error| alto):\n",
      " y_true       y_pred      abs_err  area  bedrooms  bathrooms  stories mainroad guestroom basement hotwaterheating airconditioning  parking prefarea furnishingstatus\n",
      "8750000 5,240,598.57 3,509,401.43  4320         3          1        2      yes        no      yes             yes              no        2       no   semi-furnished\n",
      "9240000 6,047,318.95 3,192,681.05  3500         4          2        2      yes        no       no             yes              no        2       no        furnished\n",
      "9240000 6,297,234.90 2,942,765.10  7800         3          2        2      yes        no       no              no              no        0      yes   semi-furnished\n",
      "7455000 4,801,338.97 2,653,661.03  4300         3          2        2      yes        no      yes              no              no        1       no      unfurnished\n",
      "6475000 3,930,932.70 2,544,067.30  3960         3          1        1      yes        no      yes              no              no        2       no   semi-furnished\n",
      "3640000 6,145,366.29 2,505,366.29  2275         3          1        3      yes        no       no             yes             yes        0      yes   semi-furnished\n",
      "5866000 3,478,023.02 2,387,976.98  4800         3          1        1      yes       yes      yes              no              no        0       no      unfurnished\n",
      "2660000 5,011,621.36 2,351,621.36  3630         3          3        2       no       yes       no              no              no        0       no      unfurnished\n",
      "9870000 7,527,834.26 2,342,165.74  8100         4          1        2      yes       yes      yes              no             yes        2      yes        furnished\n",
      "3570000 5,767,570.55 2,197,570.55  4500         4          2        2      yes        no      yes              no              no        2       no        furnished\n",
      "\n",
      "MAE por price_clase:\n",
      "             count         mean     median\n",
      "price_clase                               \n",
      "MAYOR           55 1,005,663.76 733,504.70\n",
      "MENOR           54   725,432.27 646,388.49\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "# =========================================\n",
    "# 10) Interpretabilidad + breve error analysis (mínimo, FIX)\n",
    "# =========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# --- 10.1 ¿Cuánto recorta la política? ---\n",
    "raw_pred = winner_pipe.predict(X_test)\n",
    "clip_low  = (raw_pred < POLICY[\"lower\"]).mean()\n",
    "clip_high = (raw_pred > POLICY[\"upper\"]).mean()\n",
    "print(f\"[Policy] clipped_low: {clip_low:.3%} | clipped_high: {clip_high:.3%}\")\n",
    "\n",
    "# --- 10.2 Importancias por Permutación (sobre columnas ORIGINALES) ---\n",
    "# Se permutan columnas de X_test tal cual las ve el preprocesador del pipeline.\n",
    "r = permutation_importance(\n",
    "    estimator=winner_pipe,   # pipeline completa (prep + var0 + model)\n",
    "    X=X_test, y=y_test,\n",
    "    n_repeats=10,\n",
    "    random_state=RANDOM_STATE,\n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "\n",
    "feat_names = X_test.columns  # nombres originales de entrada\n",
    "imp = (pd.DataFrame({\n",
    "        \"feature\": feat_names,\n",
    "        \"importance\": r.importances_mean,\n",
    "        \"std\": r.importances_std\n",
    "     })\n",
    "     .sort_values(\"importance\", ascending=False)\n",
    "     .head(15)\n",
    ")\n",
    "print(\"\\nTop-15 importancias (perm, columnas originales):\")\n",
    "print(imp.to_string(index=False))\n",
    "\n",
    "# --- 10.3 Errores: resumen + peores casos ---\n",
    "y_hat = winner_pipe.predict(X_test)\n",
    "y_pp  = postprocess_preds(y_hat, POLICY)\n",
    "res   = pd.DataFrame({\n",
    "    \"y_true\": y_test.reset_index(drop=True),\n",
    "    \"y_pred\": pd.Series(y_pp)\n",
    "})\n",
    "res[\"abs_err\"] = (res[\"y_true\"] - res[\"y_pred\"]).abs()\n",
    "\n",
    "print(\"\\nResumen de |error|:\")\n",
    "print(res[\"abs_err\"].describe(percentiles=[.1,.25,.5,.75,.9]).to_string())\n",
    "\n",
    "print(\"\\nPeores 10 casos (|error| alto):\")\n",
    "top_bad_idx = res[\"abs_err\"].nlargest(10).index\n",
    "print(pd.concat([res.loc[top_bad_idx], X_test.reset_index(drop=True).loc[top_bad_idx]], axis=1)\n",
    "      .to_string(index=False))\n",
    "\n",
    "# --- 10.4 Métricas por subgrupos (usando price_clase binaria que definimos en Paso 1) ---\n",
    "if \"price_clase\" in df.columns:\n",
    "    by_cls = (pd.concat([df.loc[X_test.index, \"price_clase\"].reset_index(drop=True).rename(\"price_clase\"), res], axis=1)\n",
    "              .groupby(\"price_clase\")[\"abs_err\"]\n",
    "              .agg([\"count\",\"mean\",\"median\"])\n",
    "              .sort_index())\n",
    "    print(\"\\nMAE por price_clase:\")\n",
    "    print(by_cls.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd1a25c6-9487-4f6b-9487-2e519d11675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-20 importancias (perm, espacio OHE/model):\n",
      "                             feature  importance       std\n",
      "                           num__area  182,344.97 31,838.60\n",
      "                      num__bathrooms  138,846.63 37,007.56\n",
      "                        num__stories   94,767.63 35,128.32\n",
      "                        num__parking   52,479.10 18,063.67\n",
      "                    cat__basement_no   15,260.47  4,523.72\n",
      "                   cat__basement_yes   15,260.47  4,523.72\n",
      "                    cat__prefarea_no   14,152.62 11,556.02\n",
      "                   cat__prefarea_yes   14,152.62 11,556.02\n",
      "            cat__hotwaterheating_yes    9,952.86  6,541.29\n",
      "             cat__hotwaterheating_no    9,952.86  6,541.29\n",
      "                  cat__guestroom_yes    6,497.25  4,124.01\n",
      "                   cat__guestroom_no    6,497.25  4,124.01\n",
      "                    cat__mainroad_no    4,398.90  7,844.16\n",
      "                   cat__mainroad_yes    4,398.90  7,844.16\n",
      "cat__furnishingstatus_semi-furnished    1,133.46  5,995.07\n",
      "                       num__bedrooms   -2,385.15  9,968.92\n",
      "   cat__furnishingstatus_unfurnished  -11,014.51 17,990.98\n",
      "     cat__furnishingstatus_furnished  -13,141.82 13,258.36\n",
      "             cat__airconditioning_no  -19,234.03 30,336.98\n",
      "            cat__airconditioning_yes  -19,234.03 30,336.98\n"
     ]
    }
   ],
   "source": [
    "# --- 10.5 Importancias por permutación a NIVEL OHE (alineadas con VarThreshold) ---\n",
    "# Aquí medimos sobre el espacio de features que realmente llegan al modelo (prep -> var0).\n",
    "try:\n",
    "    prep = winner_pipe.named_steps[\"prep\"]\n",
    "    var0 = winner_pipe.named_steps.get(\"var0\", None)\n",
    "    model = winner_pipe.named_steps[\"model\"]\n",
    "\n",
    "    # 1) Transformación hasta antes del modelo\n",
    "    X_prep = prep.transform(X_test)              # después de ColumnTransformer (OHE + escala)\n",
    "    feat_names_ohe_full = prep.get_feature_names_out()  # nombres OHE (num + cat expandido)\n",
    "\n",
    "    # 2) Aplicar el selector de varianza si existe (para alinear con lo que ve el modelo)\n",
    "    if var0 is not None:\n",
    "        support_mask = var0.get_support()\n",
    "        X_model_in   = var0.transform(X_prep)\n",
    "        feat_names_ohe = np.array(feat_names_ohe_full)[support_mask]\n",
    "    else:\n",
    "        X_model_in   = X_prep\n",
    "        feat_names_ohe = feat_names_ohe_full\n",
    "\n",
    "    # 3) Permutation importance en el espacio OHE ya filtrado\n",
    "    r2 = permutation_importance(\n",
    "        estimator=model,\n",
    "        X=X_model_in, y=y_test,\n",
    "        n_repeats=10,\n",
    "        random_state=RANDOM_STATE,\n",
    "        scoring=\"neg_root_mean_squared_error\"\n",
    "    )\n",
    "    imp_ohe = (pd.DataFrame({\n",
    "                \"feature\": feat_names_ohe,\n",
    "                \"importance\": r2.importances_mean,\n",
    "                \"std\": r2.importances_std\n",
    "             })\n",
    "             .sort_values(\"importance\", ascending=False)\n",
    "             .head(20))\n",
    "    print(\"\\nTop-20 importancias (perm, espacio OHE/model):\")\n",
    "    print(imp_ohe.to_string(index=False))\n",
    "except Exception as e:\n",
    "    print(f\"\\n[AVISO] No se pudo calcular importancias OHE detalladas: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17556694-e26a-4c8d-91fa-c7d84535776b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num__area</td>\n",
       "      <td>182,344.97</td>\n",
       "      <td>31,838.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num__bathrooms</td>\n",
       "      <td>138,846.63</td>\n",
       "      <td>37,007.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num__stories</td>\n",
       "      <td>94,767.63</td>\n",
       "      <td>35,128.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num__parking</td>\n",
       "      <td>52,479.10</td>\n",
       "      <td>18,063.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cat__basement_no</td>\n",
       "      <td>15,260.47</td>\n",
       "      <td>4,523.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cat__basement_yes</td>\n",
       "      <td>15,260.47</td>\n",
       "      <td>4,523.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cat__prefarea_no</td>\n",
       "      <td>14,152.62</td>\n",
       "      <td>11,556.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cat__prefarea_yes</td>\n",
       "      <td>14,152.62</td>\n",
       "      <td>11,556.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cat__hotwaterheating_yes</td>\n",
       "      <td>9,952.86</td>\n",
       "      <td>6,541.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cat__hotwaterheating_no</td>\n",
       "      <td>9,952.86</td>\n",
       "      <td>6,541.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cat__guestroom_yes</td>\n",
       "      <td>6,497.25</td>\n",
       "      <td>4,124.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cat__guestroom_no</td>\n",
       "      <td>6,497.25</td>\n",
       "      <td>4,124.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat__mainroad_no</td>\n",
       "      <td>4,398.90</td>\n",
       "      <td>7,844.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cat__mainroad_yes</td>\n",
       "      <td>4,398.90</td>\n",
       "      <td>7,844.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cat__furnishingstatus_semi-furnished</td>\n",
       "      <td>1,133.46</td>\n",
       "      <td>5,995.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num__bedrooms</td>\n",
       "      <td>-2,385.15</td>\n",
       "      <td>9,968.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cat__furnishingstatus_unfurnished</td>\n",
       "      <td>-11,014.51</td>\n",
       "      <td>17,990.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cat__furnishingstatus_furnished</td>\n",
       "      <td>-13,141.82</td>\n",
       "      <td>13,258.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cat__airconditioning_no</td>\n",
       "      <td>-19,234.03</td>\n",
       "      <td>30,336.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cat__airconditioning_yes</td>\n",
       "      <td>-19,234.03</td>\n",
       "      <td>30,336.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 feature  importance       std\n",
       "0                              num__area  182,344.97 31,838.60\n",
       "2                         num__bathrooms  138,846.63 37,007.56\n",
       "3                           num__stories   94,767.63 35,128.32\n",
       "4                           num__parking   52,479.10 18,063.67\n",
       "9                       cat__basement_no   15,260.47  4,523.72\n",
       "10                     cat__basement_yes   15,260.47  4,523.72\n",
       "15                      cat__prefarea_no   14,152.62 11,556.02\n",
       "16                     cat__prefarea_yes   14,152.62 11,556.02\n",
       "12              cat__hotwaterheating_yes    9,952.86  6,541.29\n",
       "11               cat__hotwaterheating_no    9,952.86  6,541.29\n",
       "8                     cat__guestroom_yes    6,497.25  4,124.01\n",
       "7                      cat__guestroom_no    6,497.25  4,124.01\n",
       "5                       cat__mainroad_no    4,398.90  7,844.16\n",
       "6                      cat__mainroad_yes    4,398.90  7,844.16\n",
       "18  cat__furnishingstatus_semi-furnished    1,133.46  5,995.07\n",
       "1                          num__bedrooms   -2,385.15  9,968.92\n",
       "19     cat__furnishingstatus_unfurnished  -11,014.51 17,990.98\n",
       "17       cat__furnishingstatus_furnished  -13,141.82 13,258.36\n",
       "13               cat__airconditioning_no  -19,234.03 30,336.98\n",
       "14              cat__airconditioning_yes  -19,234.03 30,336.98"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29004e26-84b4-44ac-84bb-1139c91876f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
